{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 関数読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(ans, pred):\n",
    "    return np.sqrt(np.square(np.log1p(ans) - np.log1p(pred)).mean())\n",
    "\n",
    "def rmse(ans, pred):\n",
    "    return np.sqrt(np.square(ans - pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_cat_plot(merged_data, cat_cols, n_col=2):\n",
    "    n_col = 2\n",
    "    n_row = len(cat_cols) // n_col + 1\n",
    "\n",
    "    fig, axes = plt.subplots(n_row,n_col, figsize=(n_col*6, n_row*4))\n",
    "\n",
    "    for cat_col, ax in zip(cat_cols, axes.flatten()):\n",
    "\n",
    "        tmp = pd.pivot_table(merged_data, index=cat_col,\n",
    "                                           columns=\"train\", values='age', aggfunc=\"count\")\n",
    "\n",
    "        left = np.arange(len(tmp))\n",
    "        train_ = tmp[0].values / tmp[0].values.sum()\n",
    "        test_ = tmp[1].values / tmp[1].values.sum()\n",
    "        \n",
    "        ax.bar(left, train_ , width=0.4, label=\"train\")\n",
    "        ax.bar(left+0.5, test_, width=0.4, label=\"test\")\n",
    "        \n",
    "        ax.set_ylim(0, max(train_.max(), test_.max())*1.1)\n",
    "        ax.legend()\n",
    "        ax.set_xticks(left+0.25) \n",
    "        ax.set_xticklabels(tmp.index.values)\n",
    "        ax.set_title(cat_col)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_lgbm_ensemble(train_data, params, num_round=1000, K=5):\n",
    "    kf = KFold(n_splits=K, random_state=2019, shuffle=True)\n",
    "    split = kf.split(train_data)\n",
    "    models = []\n",
    "    rmsles = []\n",
    "    for train_idx, val_idx in split:\n",
    "        train_x = train_data.drop(\"charges\", axis=1).values\n",
    "        train_y = train_data[\"charges\"].map(lambda y: np.log1p(y)).values\n",
    "        train_x, valid_x = train_x[train_idx], train_x[val_idx]\n",
    "        train_y, valid_y = train_y[train_idx], train_y[val_idx]\n",
    "\n",
    "        # 学習\n",
    "        d_train = lgbm.Dataset(train_x, label=train_y)\n",
    "        d_valid = lgbm.Dataset(valid_x, label=valid_y)\n",
    "        \n",
    "        model = lgbm.train(params = lgbm_params,\n",
    "                                           train_set =d_train,\n",
    "                                           valid_sets = d_valid,\n",
    "                                           num_boost_round = num_round,\n",
    "                                           early_stopping_rounds = 20,\n",
    "                                           verbose_eval=50)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        valid_pred = model.predict(valid_x)\n",
    "        rmsles.append(rmse(valid_y, valid_pred))\n",
    "        \n",
    "    return models, rmsles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "train_data = pd.read_csv(DATA_PATH+\"sample_train.csv\")\n",
    "test_data = pd.read_csv(DATA_PATH+\"sample_test.csv\")\n",
    "answer_data = pd.read_csv(DATA_PATH+\"sample_answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 値のチェック\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# null　チェック\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 特殊なカテゴリーがあるかチェック\n",
    "cat_cols = [\"region\", \"smoker\", \"sex\"]\n",
    "for cat_col in cat_cols:\n",
    "    print(train_data[cat_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 各種統計量\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_data,\n",
    "                     vars=[\"charges\", \"region\", \"smoker\", \"children\", \"bmi\", \"sex\", \"age\"])\n",
    "plt.savefig('data/EDA/pairplot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    sns.pairplot(train_data, hue = col,\n",
    "                         vars=[\"charges\", \"children\", \"bmi\", \"age\"])\n",
    "    plt.savefig(f'data/EDA/{col}_pairplot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train, testの分布を確認\n",
    "train_data[\"train\"] = 1\n",
    "test_data[\"train\"] = 0\n",
    "merged_data = pd.concat([train_data, test_data], sort=False)\n",
    "\n",
    "sns.pairplot(merged_data, hue=\"train\",\n",
    "                     vars=[\"children\", \"bmi\", \"age\"])\n",
    "plt.savefig(f'data/EDA/train_test_pairplot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_test_cat_plot(merged_data,  cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベースライン\n",
    "KFold Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"children\"] = train_data[\"children\"].map(lambda x : str(x))\n",
    "test_data[\"children\"] = test_data[\"children\"].map(lambda x : str(x))\n",
    "\n",
    "train_data = train_data.drop(\"id\", axis=1)\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"n_estimators\": 1000,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': -1, \n",
    "    \"num_threads\": 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シングルモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, random_state=2019, shuffle=True)\n",
    "split = kf.split(train_data)\n",
    "train_idx, val_idx = split.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = train_data.drop(\"charges\", axis=1).values\n",
    "train_y = train_data[\"charges\"].map(lambda y: np.log1p(y)).values\n",
    "train_x, valid_x = train_x[train_idx], train_x[val_idx]\n",
    "train_y, valid_y = train_y[train_idx], train_y[val_idx]\n",
    "\n",
    "# 学習\n",
    "d_train = lgbm.Dataset(train_x, label=train_y)\n",
    "d_valid = lgbm.Dataset(valid_x, label=valid_y)\n",
    "model = lgbm.train(params = lgbm_params,\n",
    "                                   train_set =d_train,\n",
    "                                   valid_sets = d_valid,\n",
    "                                   num_boost_round = 1000,\n",
    "                                   early_stopping_rounds = 20,\n",
    "                                   verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Leaderboard\n",
    "0.4154697625778434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_data.values)\n",
    "test_pred = np.exp(test_pred) - 1\n",
    "print(rmsle(answer_data[\"charges\"].values, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_rmsles = []\n",
    "for i in range(9):\n",
    "    K =i+2\n",
    "    models, rmsles = KFold_lgbm_ensemble(train_data, lgbm_params, K=K)\n",
    "    cv_rmsles.append(np.mean(rmsles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_rmsles)\n",
    "plt.xticks(np.arange(10), np.arange(10)+2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Leaderboard\n",
    "0.41444564295755526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 8\n",
    "models, rmsles = KFold_lgbm_ensemble(train_data, lgbm_params, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.zeros(test_data.values.shape[0])\n",
    "for model in models:\n",
    "    test_pred_ = model.predict(test_data.values)\n",
    "    test_pred_ = np.exp(test_pred_) - 1\n",
    "    test_pred += test_pred_\n",
    "test_pred = test_pred / K\n",
    "\n",
    "print(rmsle(answer_data[\"charges\"].values, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgbm with Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_noise(array, noise_level=0.2):\n",
    "    '''(i, j)要素を確率的に(i', j)に変えるノイズ\n",
    "    '''\n",
    "    n_row, n_col = merged_data.values.shape\n",
    "    rands = np.random.uniform(0, 1, size=(n_row, n_col))\n",
    "    copy_array = np.array(merged_data.values)\n",
    "    for col in range(n_col):\n",
    "        for row in range(n_row):\n",
    "            if rands[row, col] < noise_level:\n",
    "                swap_target_row = np.random.randint(0, n_row)\n",
    "                copy_array[row, col] = array[swap_target_row, col]\n",
    "    return copy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100) # 取得する中間表現\n",
    "        self.fc4 = nn.Linear(100, 100)\n",
    "        self.fc5 = nn.Linear(100, input_size)\n",
    "        # 初期化\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        h = self.relu(self.fc2(h))\n",
    "        h = self.relu(self.fc3(h))\n",
    "        h = self.relu(self.fc4(h))\n",
    "        out = self.fc5(h)\n",
    "        return out\n",
    "    \n",
    "    def get_representation(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        h = self.relu(self.fc2(h))\n",
    "        h = self.relu(self.fc3(h))\n",
    "        return h\n",
    "\n",
    "def train(model, data_loader, loss_func, optimizer, device=torch.device(\"cpu\")):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for row_data in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        row_data = row_data.to(device)\n",
    "        outputs = model(row_data)\n",
    "        loss = loss_func(outputs, row_data)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss / len(data_loader)\n",
    "    return train_loss\n",
    "\n",
    "def get_representation(model, array):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.Tensor(array)\n",
    "        outputs = model.get_representation(inputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.data_num = self.data.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "train_data = pd.read_csv(DATA_PATH+\"sample_train.csv\")\n",
    "test_data = pd.read_csv(DATA_PATH+\"sample_test.csv\")\n",
    "train_y = train_data[\"charges\"].values\n",
    "\n",
    "num_cols = [\"bmi\", \"age\"]\n",
    "cat_cols = [\"children\", \"region\", \"smoker\", \"sex\"]\n",
    "\n",
    "# dae用にmerge\n",
    "train_data[\"train\"] = 1\n",
    "test_data[\"train\"] = 0\n",
    "merged_data = pd.concat([train_data, test_data], sort=False)\n",
    "train_flag = merged_data[\"train\"].values\n",
    "merged_data = merged_data.drop([\"id\", \"charges\", \"train\"], axis=1)\n",
    "merged_data[\"children\"] = merged_data[\"children\"].map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankgauss\n",
    "rankgauss_transformer = QuantileTransformer(n_quantiles = 100, random_state=2019,\n",
    "                                                                                  output_distribution=\"normal\")\n",
    "merged_data[num_cols] = rankgauss_transformer.fit_transform(merged_data[num_cols])\n",
    "\n",
    "# one hot\n",
    "noised_merged_data = pd.DataFrame(swap_noise(merged_data.values),\n",
    "                                                                  columns=merged_data.columns)\n",
    "noised_merged_data = pd.get_dummies(noised_merged_data, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TableData(noised_merged_data.values.astype(\"float32\"))\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu/cpu\n",
    "device = torch.device(\"cuda:9\")\n",
    "\n",
    "# モデル\n",
    "input_size = noised_merged_data.values.shape[1]\n",
    "dae_model = AutoEncoder(input_size)\n",
    "dae_model = dae_model.to(device)\n",
    "\n",
    "#Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(dae_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(train(dae_model, loader, criterion, optimizer, device))\n",
    "dae_model.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DAEによる変換\n",
    "\n",
    "# test, trainで同様の変換になるように\n",
    "merged_data[\"train\"] = train_flag\n",
    "one_hot_merged_data = pd.get_dummies(merged_data, columns=cat_cols)\n",
    "train_x = one_hot_merged_data.query(\"train == 1\").drop(\"train\", axis=1)\n",
    "test_x = one_hot_merged_data.query(\"train == 0\").drop(\"train\", axis=1)\n",
    "\n",
    "# 変換\n",
    "train_x = get_representation(dae_model, train_x.values).numpy()\n",
    "test_x =  get_representation(dae_model, test_x.values).numpy()\n",
    "train_data_ = pd.DataFrame(train_x)\n",
    "train_data_[\"charges\"] = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シングルモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"n_estimators\": 1000,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': -1, \n",
    "    \"num_threads\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, random_state=2019, shuffle=True)\n",
    "split = kf.split(train_data_)\n",
    "train_idx, val_idx = split.__next__()\n",
    "\n",
    "train_x = train_data_.drop(\"charges\", axis=1).values\n",
    "train_y = train_data_[\"charges\"].map(lambda y: np.log1p(y)).values\n",
    "train_x, valid_x = train_x[train_idx], train_x[val_idx]\n",
    "train_y, valid_y = train_y[train_idx], train_y[val_idx]\n",
    "\n",
    "# 学習\n",
    "d_train = lgbm.Dataset(train_x, label=train_y)\n",
    "d_valid = lgbm.Dataset(valid_x, label=valid_y)\n",
    "model = lgbm.train(params = lgbm_params,\n",
    "                                   train_set =d_train,\n",
    "                                   valid_sets = d_valid,\n",
    "                                   num_boost_round = 1000,\n",
    "                                   early_stopping_rounds = 20,\n",
    "                                   verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Leaderbord\n",
    "0.4840280135653281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_x)\n",
    "test_pred = np.exp(test_pred) - 1\n",
    "print(rmsle(answer_data[\"charges\"].values, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Ensembel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_rmsles = []\n",
    "for i in range(9):\n",
    "    K =i+2\n",
    "    models, rmsles = KFold_lgbm_ensemble(train_data_, lgbm_params, K=K)\n",
    "    cv_rmsles.append(np.mean(rmsles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_rmsles)\n",
    "plt.xticks(np.arange(10), np.arange(10)+2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Leaderbord\n",
    "0.4649929851114924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 8\n",
    "models, rmsles = KFold_lgbm_ensemble(train_data_, lgbm_params, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.zeros(test_x.shape[0])\n",
    "for model in models:\n",
    "    test_pred_ = model.predict(test_x)\n",
    "    test_pred_ = np.exp(test_pred_) - 1\n",
    "    test_pred += test_pred_\n",
    "test_pred = test_pred / K\n",
    "\n",
    "print(rmsle(answer_data[\"charges\"].values, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
